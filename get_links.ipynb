{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import logging\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import math\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "header section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/117.0',\n",
    "    'Accept':'text/html, */*; q=0.01',\n",
    "    'Accept-Language':'en-US,en;q=0.5',\n",
    "    'X-Requested-With':'XMLHttpRequest'\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran_ketab_url='https://www.iranketab.ir'\n",
    "all_books_url='/book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_for_page(page_number, timeout):\n",
    "        response=requests.post(url='https://www.iranketab.ir/book' ,headers=headers,json={'pagenumber':str(page_number),'pagesize':20},timeout=timeout)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_tags_from_iranKetab(total_pages_number:int,pages_arr):\n",
    "        \n",
    "        out=[]               #output of threads-thread's result\n",
    "        result_list=[]       #list of all book's atag\n",
    "        count_of_request=100  #number of requests sent to the website at each iteration \n",
    "        \n",
    "        #maximum number of requests(iterations) because maybe we have limited time, i do not use it here also\n",
    "        max_number_request=math.ceil((total_pages_number*2)/count_of_request)\n",
    "        count = 0\n",
    "        workers=40  #number of threads\n",
    "        sleep_time=1\n",
    "\n",
    "        # pbar = tqdm(total=count_first_keyword_list, desc=\"Request to get suggestion titles of job\")\n",
    "        # while (len(pages_arr)) and (count <= max_number_request):\n",
    "        while (len(pages_arr)):\n",
    "                sleep(sleep_time)\n",
    "                #update req_list\n",
    "                if len(pages_arr) > count_of_request:\n",
    "                    req_list =pages_arr[:count_of_request].copy()\n",
    "                else:\n",
    "                    req_list = pages_arr.copy()\n",
    "\n",
    "                with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "                    future_to_url = (executor.submit(call_for_page, pg_number, 30) for pg_number in req_list)\n",
    "                    for future in as_completed(future_to_url):\n",
    "                        try:\n",
    "                            data = future.result()\n",
    "                            out.append(data)\n",
    "                        except Exception as exc:\n",
    "                            continue\n",
    "\n",
    "                for item in out:\n",
    "                    if item.status_code == 200:\n",
    "                        this_page_number=int(json.loads(item.request.body)['pagenumber'])\n",
    "                        if this_page_number in req_list:\n",
    "                            print('page '+str(this_page_number)+' html added to result')\n",
    "                            result_list.extend(BeautifulSoup(item.content,'html.parser').select('div.col-lg-6 > div > div > div > h4 > a '))\n",
    "                            pages_arr=np.delete(pages_arr,np.where(pages_arr==this_page_number))\n",
    "\n",
    "                # count += 1\n",
    "                # pbar.update(count_last_keyword_list - len(keyword_list))\n",
    "        return result_list,pages_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_pages(url):\n",
    "    response=requests.post(url=url,headers=headers,json={'pagenumber':1,'pagesize':20})\n",
    "    soup=BeautifulSoup(response.content,'html.parser')\n",
    "    total_pages=int(re.split('\\\\=|\\\\&',soup.\n",
    "                                        select('.PagedList-skipToLast > a:nth-child(1)')[0].\\\n",
    "                                                                                           get('url'))[1])\n",
    "    return total_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_book_links(total_pages_num):\n",
    "     pages_arr=np.arange(1,total_pages_num+1)\n",
    "     all_tags,not_scraped_pages=get_a_tags_from_iranKetab(total_pages_num,pages_arr)\n",
    "     while len(not_scraped_pages)!=0:\n",
    "        new_a_tags,not_scraped_pages=get_a_tags_from_iranKetab(total_pages_num,not_scraped_pages)\n",
    "        all_tags.extend(new_a_tags)\n",
    "     all_tags=list(set(all_tags))\n",
    "     return all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_into_csv(book_links) :\n",
    "    import csv\n",
    "    with open('books_url.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['link'])\n",
    "            writer.writerows([[iran_ketab_url+item] for item in book_links])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_link():\n",
    "    total_pages_num=get_num_pages(iran_ketab_url+all_books_url)\n",
    "    book_tags=find_book_links(total_pages_num)\n",
    "    book_links=[]\n",
    "    for a_tag in book_tags:\n",
    "        book_links.append(a_tag.get('href'))\n",
    "    save_into_csv(book_links)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 html added to result\n",
      "page 12 html added to result\n",
      "page 5 html added to result\n",
      "page 19 html added to result\n",
      "page 3 html added to result\n",
      "page 17 html added to result\n",
      "page 4 html added to result\n",
      "page 7 html added to result\n",
      "page 10 html added to result\n",
      "page 6 html added to result\n",
      "page 11 html added to result\n",
      "page 20 html added to result\n",
      "page 36 html added to result\n",
      "page 28 html added to result\n",
      "page 26 html added to result\n",
      "page 37 html added to result\n",
      "page 32 html added to result\n",
      "page 30 html added to result\n",
      "page 45 html added to result\n",
      "page 42 html added to result\n",
      "page 34 html added to result\n",
      "page 41 html added to result\n",
      "page 46 html added to result\n",
      "page 15 html added to result\n",
      "page 16 html added to result\n",
      "page 2 html added to result\n",
      "page 14 html added to result\n",
      "page 25 html added to result\n",
      "page 18 html added to result\n",
      "page 21 html added to result\n",
      "page 9 html added to result\n",
      "page 43 html added to result\n",
      "page 29 html added to result\n",
      "page 8 html added to result\n",
      "page 22 html added to result\n",
      "page 35 html added to result\n",
      "page 47 html added to result\n",
      "page 23 html added to result\n",
      "page 38 html added to result\n",
      "page 49 html added to result\n",
      "page 44 html added to result\n",
      "page 50 html added to result\n"
     ]
    }
   ],
   "source": [
    "get_book_link()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
