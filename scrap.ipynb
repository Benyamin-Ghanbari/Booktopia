{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:35.730006500Z",
     "start_time": "2023-09-24T18:35:35.682980400Z"
    }
   },
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import logging\n",
    "import concurrent.futures\n",
    "import threading\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6c2e65b93bcafb3c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:44.421218900Z",
     "start_time": "2023-09-24T18:35:44.392444200Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_links():\n",
    "    urls = list(pd.read_csv('books_url.csv')['link'])\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe12b9fe14593376",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:44.862034700Z",
     "start_time": "2023-09-24T18:35:44.828891300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response(input_url):\n",
    "    headers = {\n",
    "        'User-Agent': 'My User Agent 1.0',\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\"\n",
    "    }\n",
    "    response = requests.get(input_url, headers=headers)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd775c4290d33dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:45.272412Z",
     "start_time": "2023-09-24T18:35:45.248470800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_soup(input_url):\n",
    "    headers = {\n",
    "        'User-Agent': 'My User Agent 1.0',\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\"\n",
    "    }\n",
    "    response = requests.get(input_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error in getting link\")\n",
    "        print(\"response code is : \", response.status_code)\n",
    "    book_urls.remove(page_url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "efc3968719f0d788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:45.711309900Z",
     "start_time": "2023-09-24T18:35:45.685377100Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fa_title(soup):\n",
    "    title = soup.select('.product-name strong')[0]\n",
    "    return title.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2c4dab072bbbc2ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:46.067512600Z",
     "start_time": "2023-09-24T18:35:46.033740Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_en_title(soup):\n",
    "    title = soup.select('.product-name-englishname')[0]\n",
    "    return title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5c6151c0ff09fc3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:46.411993200Z",
     "start_time": "2023-09-24T18:35:46.381357200Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_price(soup):\n",
    "    price = soup.select('.price-broken , .col-md-7 .price:nth-child(1)')[0].text\n",
    "    return int(price.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "20dfbbc77ef0ea67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:46.710341600Z",
     "start_time": "2023-09-24T18:35:46.686405600Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_discount(soup):\n",
    "    try:\n",
    "        discount_price = int(soup.select('.col-md-12+ .clearfix .price-special')[0].text.replace(',', ''))\n",
    "        discount_price = ((get_price(soup) - discount_price) / get_price(soup)) * 100\n",
    "    except Exception:\n",
    "        discount_price = 0\n",
    "        logging.exception(\"This book has no discount!\")\n",
    "    return discount_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3b95900da3f89757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:47.054397600Z",
     "start_time": "2023-09-24T18:35:47.029461800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_score(soup):\n",
    "    soup = soup.find('div', {'class': 'col-md-7'}).find('li', {'class': 'pull-left'}).find('div',\n",
    "                                                                                           {'class': 'my-rating'})\n",
    "    soup_str = str(soup)\n",
    "\n",
    "    match = re.search(r'data-rating=\"(\\d+\\.\\d+)\"', soup_str)\n",
    "    if match:\n",
    "        data_rating = match.group(1)\n",
    "        return data_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c5c9ddc5b07b81e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:47.707828100Z",
     "start_time": "2023-09-24T18:35:47.682992Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_publisher(soup):\n",
    "    try:\n",
    "        publisher_tag = soup.select('div.prodoct-attribute-items:nth-child(1) > a')[0]\n",
    "        publisher_link = publisher_tag.get('href')\n",
    "        publisher_id = publisher_link.split('/')[2].split('-')[0]\n",
    "        publisher_name = publisher_tag.text.strip()\n",
    "    except Exception:\n",
    "        publisher_link = -1\n",
    "        publisher_id = -1\n",
    "        publisher_name = -1\n",
    "    return {'id': publisher_id, 'name': publisher_name, 'link': publisher_link}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "235a6bc598b6b7ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:48.136545300Z",
     "start_time": "2023-09-24T18:35:48.104888900Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_author(soup):\n",
    "    authors_list = []\n",
    "    try:\n",
    "        authors_a_tag = soup.select('.prodoct-attribute-items+ .prodoct-attribute-items > a')\n",
    "        if (len(authors_a_tag)) == 0:\n",
    "            return authors_list\n",
    "        for author_a_tag in authors_a_tag:\n",
    "            author_link = author_a_tag.get('href')\n",
    "            author_id = author_link.split('/')[2].split('-')[0]\n",
    "            author_name = author_a_tag.text.strip()\n",
    "            authors_list.append({'id': author_id, 'name': author_name, 'link': author_link})\n",
    "    except Exception:\n",
    "        authors_list = -1\n",
    "    return authors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b21b1fa78bdd0d0e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:48.517590700Z",
     "start_time": "2023-09-24T18:35:48.490594400Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_author_available(soup):\n",
    "    try:\n",
    "        existence = soup.select('.pull-left+ li span')[0].text\n",
    "    except:\n",
    "        existence = None\n",
    "        logging.exception(\"This book has no author!\")\n",
    "    return existence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91a45fd031eab930",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:48.916363900Z",
     "start_time": "2023-09-24T18:35:48.887736400Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_book_attribute(soup):\n",
    "    rows = soup.find('table', {'class': 'product-table'}).findAll('td')\n",
    "    code = -1\n",
    "    isbn = -1\n",
    "    size = -1\n",
    "    pages = -1\n",
    "    per_cal = -1\n",
    "    ad_cal = -1\n",
    "    material = -1\n",
    "    series = -1\n",
    "    send_time = -1\n",
    "    language = 'فارسی'\n",
    "    code_flag = 0\n",
    "    isbn_flag = 0\n",
    "    size_flag = 0\n",
    "    pages_flag = 0\n",
    "    per_cal_flag = 0\n",
    "    ad_cal_flag = 0\n",
    "    material_flag = 0\n",
    "    language_flag = 0\n",
    "    series_flag = 0\n",
    "    send_time_flag = 0\n",
    "\n",
    "    for row in rows:\n",
    "        text = row.text.strip()\n",
    "        if code_flag == 1:\n",
    "            code = int(text)\n",
    "            code_flag = 0\n",
    "        elif isbn_flag == 1:\n",
    "            isbn = text\n",
    "            isbn = re.sub('[^0-9-]', '', isbn)\n",
    "            isbn_flag = 0\n",
    "        elif size_flag == 1:\n",
    "            size = text\n",
    "            size_flag = 0\n",
    "        elif pages_flag == 1:\n",
    "            pages = int(text)\n",
    "            pages_flag = 0\n",
    "        elif per_cal_flag == 1:\n",
    "            per_cal = int(text)\n",
    "            per_cal_flag = 0\n",
    "        elif ad_cal_flag == 1:\n",
    "            ad_cal = int(text)\n",
    "            ad_cal_flag = 0\n",
    "        elif material_flag == 1:\n",
    "            material = text\n",
    "            material_flag = 0\n",
    "        elif language_flag == 1:\n",
    "            language = text\n",
    "            language_flag = 0\n",
    "        elif series_flag == 1:\n",
    "            series = int(text)\n",
    "            series_flag = 0\n",
    "        elif send_time_flag == 1:\n",
    "            send_time = text\n",
    "            send_time_flag = 0\n",
    "\n",
    "        if 'کد کتاب' in text:\n",
    "            code_flag = 1\n",
    "        elif 'شابک' in text:\n",
    "            isbn_flag = 1\n",
    "        elif 'قطع' in text:\n",
    "            size_flag = 1\n",
    "        elif 'تعداد صفحه' in text:\n",
    "            pages_flag = 1\n",
    "        elif 'سال انتشار شمسی' in text:\n",
    "            per_cal_flag = 1\n",
    "        elif 'سال انتشار میلادی' in text:\n",
    "            ad_cal_flag = 1\n",
    "        elif 'نوع جلد' in text:\n",
    "            material_flag = 1\n",
    "        elif 'زبان کتاب' in text:\n",
    "            language_flag = 1\n",
    "        elif 'سری چاپ' in text:\n",
    "            series_flag = 1\n",
    "        elif 'زودترین زمان ارسال' in text:\n",
    "            send_time_flag = 1\n",
    "\n",
    "    return [code, isbn, size, pages, per_cal, ad_cal, material, language, series, send_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5c297eef97f3ef6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:49.272278500Z",
     "start_time": "2023-09-24T18:35:49.244497300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_summary(soup):\n",
    "    summary = soup.select('.product-description')[0].text.strip()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9680a41c872e4ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:49.631836300Z",
     "start_time": "2023-09-24T18:35:49.596358700Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tags(soup):\n",
    "    tags = soup.select('.product-tags-item')\n",
    "    tags_list = []\n",
    "    for tag in tags:\n",
    "        tags_list += [tag.text.strip()]\n",
    "    return tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b487ed5aba32bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:49.994011900Z",
     "start_time": "2023-09-24T18:35:49.927774400Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_book_detail(book_soup, site_index):\n",
    "    book_fa_title = get_fa_title(book_soup)\n",
    "    book_en_title = get_en_title(book_soup)\n",
    "    book_price = get_price(book_soup)\n",
    "    book_discount_percent = get_discount(book_soup)\n",
    "    book_score = get_score(book_soup)\n",
    "    book_publisher = get_publisher(book_soup)\n",
    "    book_author = get_author(book_soup)\n",
    "    book_author_presence = is_author_available(book_soup)\n",
    "\n",
    "    [book_code, book_isbn, book_size, book_pages, book_publication_per_date, book_publication_ad_date,\n",
    "     book_cover_material, book_language, book_print_series, book_earliest_send_time] = get_book_attribute(book_soup)\n",
    "\n",
    "    book_data = [site_index, int(book_code), book_isbn, book_fa_title, book_en_title, book_price,\n",
    "                 int(book_discount_percent), book_score, book_publisher, book_author, int(book_pages),\n",
    "                 int(book_publication_per_date), int(book_publication_ad_date), book_size, book_cover_material,\n",
    "                 book_language, int(book_print_series), book_earliest_send_time, book_author_presence]\n",
    "    return book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "52bb9e3fa91b9548",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:50.336743500Z",
     "start_time": "2023-09-24T18:35:50.308980800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_book_site_summary(book_soup, site_index):\n",
    "    try:\n",
    "        book_summary = get_summary(book_soup)\n",
    "    except Exception:\n",
    "        book_summary = None\n",
    "        logging.exception(\"This book has no summary!\")\n",
    "    return [site_index, book_summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12597cd1c3c3e9f5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:50.677770800Z",
     "start_time": "2023-09-24T18:35:50.654810700Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_book_site_tags(book_soup, site_index):\n",
    "    book_tags = get_tags(book_soup)\n",
    "    book_tags_list = []\n",
    "    for tag in book_tags:\n",
    "        book_tags_list += [[site_index, tag]]\n",
    "    return book_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "33fc61291443bf82",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:51.021659900Z",
     "start_time": "2023-09-24T18:35:50.989422200Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_site_awards(soup, site_index):\n",
    "    awards_list = []\n",
    "    awards = soup.select('book_soup, site_index')\n",
    "\n",
    "    for award in awards:\n",
    "        print(award.text)\n",
    "        awards += [award.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e410df15deddef2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:51.365463400Z",
     "start_time": "2023-09-24T18:35:51.338715300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_req_list(list, req_count):\n",
    "    if len(list) >= req_count:\n",
    "        request_list = list[:req_count].copy()\n",
    "    else:\n",
    "        request_list = list.copy()\n",
    "    return request_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6765fb21ffc5eee4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:51.729626300Z",
     "start_time": "2023-09-24T18:35:51.705155700Z"
    }
   },
   "outputs": [],
   "source": [
    "def scrape(site_soup):\n",
    "    try:\n",
    "        with lock:\n",
    "            global site_index\n",
    "            site_summary_data_list.append(get_book_site_summary(site_soup, site_index))\n",
    "            site_tags_data_list.extend(get_book_site_tags(site_soup, site_index))\n",
    "            site_page_books = site_soup.select('.clearfix .clearfix .row')\n",
    "            for book_index in range(0, len(site_page_books), 2):\n",
    "                data = get_book_detail(site_page_books[book_index], site_index)\n",
    "                books_data_list.append(data)\n",
    "            site_index += 1\n",
    "    except Exception:\n",
    "        logging.exception(\"An error occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "113b8344e2efc33f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:35:55.062923600Z",
     "start_time": "2023-09-24T18:35:55.053946600Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_scrape(link):\n",
    "    try:\n",
    "        site_soup = get_soup(link)\n",
    "        with lock:\n",
    "            global site_index\n",
    "            site_summary_data_list.append(get_book_site_summary(site_soup, site_index))\n",
    "            site_tags_data_list.extend(get_book_site_tags(site_soup, site_index))\n",
    "            site_page_books = site_soup.select('.clearfix .clearfix .row')\n",
    "            for book_index in range(0, len(site_page_books), 2):\n",
    "                data = get_book_detail(site_page_books[book_index], site_index)\n",
    "                writers_data_list.extend(data[9])     #9th index is the writer column which is a list of writers\n",
    "                publishers_data_list.append(data[8])  #8th column is dict of publisher\n",
    "                data[8]=data[8]['id']                 #convert 8th column from dict to the publisher's id\n",
    "                writers_list_of_dict=data[9]          #writes list which is a list of dictionary\n",
    "                data.pop(9)                           #remove 9th column from data(9th column was writers)\n",
    "                for w_id in writers_list_of_dict:\n",
    "                     books_writers_data_list.append({'book_id':data[1],'writer_id':w_id['id']})\n",
    "                books_data_list.append(data)\n",
    "            site_index += 1\n",
    "    except Exception:\n",
    "        logging.exception(\"An error occurred\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba91c7d84afba5a4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Detailed Scraper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a609902c961aa8e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "links = get_links()[:200] + ['https://www.iranketab.ir/book/270-gone-with-the-wind']\n",
    "\n",
    "page_response = []\n",
    "books_data_list = []\n",
    "site_tags_data_list = []\n",
    "site_summary_data_list = []\n",
    "\n",
    "site_index = 1\n",
    "sleep_time = 0.5\n",
    "max_threads = 20\n",
    "book_count_request = 20  #number of requests per time\n",
    "\n",
    "lock = threading.Lock()\n",
    "book_urls = links.copy()\n",
    "\n",
    "while len(book_urls):\n",
    "    sleep(sleep_time)  #sleep so that the site does not ban us\n",
    "    request_list = get_req_list(book_urls, book_count_request)  #list of book's urls we want to send request \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        future_list = executor.map(get_response, request_list)\n",
    "        for future in future_list:\n",
    "            try:\n",
    "                data = future\n",
    "                page_response.append(data)\n",
    "            except Exception as exc:\n",
    "                continue\n",
    "        for item in page_response:\n",
    "            if item.status_code == 200:\n",
    "                page_url = item.url\n",
    "                if page_url in request_list:\n",
    "                    page_soup = bs4.BeautifulSoup(item.content, 'html.parser')\n",
    "                    scrape(page_soup)\n",
    "                    book_urls.remove(page_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6191d96283542fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Fast Scraper</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8d0c478f6decda4a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:39:06.706439800Z",
     "start_time": "2023-09-24T18:39:05.701609900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n",
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\3854377785.py\", line 3, in fast_scrape\n",
      "    [site_links, site_soup] = get_soup(link, site_links)\n",
      "  File \"C:\\Users\\raeim\\AppData\\Local\\Temp\\ipykernel_5524\\291745038.py\", line 10, in get_soup\n",
      "    book_links.remove(page_url)\n",
      "AttributeError: 'str' object has no attribute 'remove'\n"
     ]
    }
   ],
   "source": [
    "links = get_links()[:200] + ['https://www.iranketab.ir/book/270-gone-with-the-wind']\n",
    "\n",
    "books_data_list = []\n",
    "site_tags_data_list = []\n",
    "site_summary_data_list = []\n",
    "writers_data_list = []\n",
    "publishers_data_list = []\n",
    "books_writers_data_list = []\n",
    "\n",
    "site_index = 1\n",
    "max_threads = 20\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "    executor.map(fast_scrape, links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8d25f005a8c2c8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Check Completnes</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "61f7e5ebf2342413",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T18:39:11.190581200Z",
     "start_time": "2023-09-24T18:39:11.169126500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something wrong happened! Missed  11 links while scraping.\n"
     ]
    }
   ],
   "source": [
    "if len(book_urls) == 0:\n",
    "    print('All links scraped!')\n",
    "else:\n",
    "    print('Something wrong happened!',len(book_urls),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1d4d155e402ba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Make Dataframes</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad990b979ac7f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableOfData = pd.DataFrame(books_data_list,\n",
    "                           columns=['site_index', 'code', 'Isbn', 'fa_title', 'en_title', 'price', 'discount', 'score',\n",
    "                                    'publisher', 'author', 'pages', 'publication_per_date', 'publication_ad_date',\n",
    "                                    'size', 'cover_material', 'print_series', 'language', 'earliest_send_time',\n",
    "                                    'presence'])\n",
    "tableOfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f94ddb4454136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"bookData.csv\"\n",
    "tableOfData.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49865f3f491e2893",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tableOfSummaryData = pd.DataFrame(site_summary_data_list, columns=['site_index', 'summary'])\n",
    "tableOfSummaryData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181915a808b0a33",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = \"BookSummaryData.csv\"\n",
    "tableOfData.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb17a40b865591",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tableOfSiteTagsData = pd.DataFrame(site_tags_data_list, columns=['site_index', 'tag'])\n",
    "tableOfSiteTagsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ebe5799696472",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = \"bookTagsData.csv\"\n",
    "tableOfData.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3b338aab9ca3b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_of_publishers = pd.DataFrame(publishers_data_list).drop_duplicates(subset=['id', 'name', 'link'])\n",
    "table_of_publishers.to_csv('./publishers.csv', index=False)\n",
    "table_of_publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_of_writers = pd.DataFrame(writers_data_list).drop_duplicates(subset=['id', 'name', 'link'])\n",
    "table_of_writers.to_csv('./writers.csv', index=False)\n",
    "table_of_writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c3505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
